================================================================================
                    INTERACTIVE SQL OPTIMIZATION CLI
                           Usage Guide
================================================================================

OVERVIEW
--------
The optimize_cli.py tool provides an interactive interface for demonstrating
autonomous SQL query optimization. It shows detailed traces of the agent's
reasoning, feedback analysis, and optimization actions.

FEATURES
--------
✓ Interactive query input (multi-line support)
✓ Real-time optimization traces
✓ Detailed feedback and reasoning display
✓ Performance metrics visualization
✓ Action history and final results
✓ Full color-coded terminal output

REQUIREMENTS
------------
1. Python 3.10+
2. PostgreSQL database (accessible via connection string)
3. Anthropic API key (export ANTHROPIC_API_KEY='your-key')
4. Installed dependencies (pip install -e .)

BASIC USAGE
-----------

1. Set up your environment:

   export ANTHROPIC_API_KEY='sk-ant-...'
   export DB_CONNECTION='postgresql://localhost/mydb'

2. Run the CLI:

   python optimize_cli.py

3. Enter your SQL query (multi-line supported):

   SELECT * FROM users WHERE email = 'test@example.com'
   GO

4. Watch the agent optimize your query!

COMMAND LINE OPTIONS
--------------------

--db-connection <url>
    PostgreSQL connection string
    Default: $DB_CONNECTION or postgresql://localhost/testdb

    Example: postgresql://user:pass@localhost:5432/mydb

--max-iterations <n>
    Maximum optimization iterations
    Default: 5

    Recommended: 3-7 for most queries

--max-cost <float>
    Maximum acceptable query cost
    Default: 10000.0

    Adjust based on your performance requirements

--max-time-ms <milliseconds>
    Maximum execution time in milliseconds
    Default: 30000 (30 seconds)

--analyze-cost-threshold <float>
    Only run EXPLAIN ANALYZE if estimated cost is below this
    Default: 5000000.0

    Higher values allow ANALYZE on expensive queries (risky)

EXAMPLES
--------

Example 1: Basic usage with local database

    python optimize_cli.py \
      --db-connection postgresql://localhost/testdb

Example 2: Production database with strict constraints

    python optimize_cli.py \
      --db-connection postgresql://user:pass@prod-db:5432/analytics \
      --max-cost 1000 \
      --max-time-ms 5000 \
      --max-iterations 3

Example 3: Development mode with relaxed constraints

    python optimize_cli.py \
      --db-connection postgresql://localhost/dev_db \
      --max-cost 50000 \
      --max-iterations 10

SAMPLE SESSION
--------------

$ python optimize_cli.py --db-connection postgresql://localhost/testdb

================================================================================
                   INTERACTIVE SQL OPTIMIZATION CLI
================================================================================

Configuration:
  Database: postgresql://localhost/testdb
  Max Iterations: 5
  Max Cost: 10000.0
  Max Time: 30000ms

Instructions:
  • Enter your SQL query (multi-line supported)
  • Type 'GO' on a new line to execute
  • Type 'EXIT' or 'QUIT' to quit
  • Press Ctrl+C to interrupt

Enter SQL query (type 'GO' to execute, 'EXIT' to quit):
SELECT * FROM orders
WHERE customer_id = 12345
AND order_date >= '2024-01-01'
GO

================================================================================
                        SQL OPTIMIZATION SESSION
================================================================================

Query:
SELECT * FROM orders WHERE customer_id = 12345 AND order_date >= '2024-01-01'

Database: postgresql://localhost/testdb
Constraints:
  • max_cost: 10000.0
  • max_time_ms: 30000
  • analyze_cost_threshold: 5000000.0

▶ Starting Autonomous Optimization
────────────────────────────────────────────────────────────────────────────

▶ Iteration 1: Analyzing Query
────────────────────────────────────────────────────────────────────────────
Current Query: SELECT * FROM orders WHERE customer_id = 12345 AND order_date >= '2024-01-01'

Performance Analysis:
  Status: FAIL
  Total Cost: 45,072.50

Feedback:
  Priority: HIGH
  Reason: Sequential scan detected on large table

Bottlenecks Detected:
  1. [HIGH] Seq Scan: Sequential scan on 'orders' with 50,000 rows
     CREATE INDEX idx_orders_composite ON orders(customer_id, order_date);

▶ Planning Next Action
────────────────────────────────────────────────────────────────────────────

Agent Decision:
  Action Type: CREATE_INDEX
  Confidence: 95%

Reasoning:
  The query performs a sequential scan on the orders table. Creating a
  composite index on (customer_id, order_date) will enable index scan
  and significantly improve performance.

DDL Statement:
  CREATE INDEX idx_orders_composite ON orders(customer_id, order_date);

Executing: CREATE INDEX idx_orders_composite ON orders(customer_id, order_date);
✓ Execution successful

... (further iterations) ...

================================================================================
                         OPTIMIZATION COMPLETE
================================================================================

✓ Optimization successful: Query optimized successfully

Summary:
  Total Iterations: 2
  Actions Taken: 1

Final Query:
SELECT * FROM orders WHERE customer_id = 12345 AND order_date >= '2024-01-01'

▶ Action History
────────────────────────────────────────────────────────────────────────────
✓ Step 1: CREATE_INDEX
  Sequential scan detected. Creating index to improve performance.
  DDL: CREATE INDEX idx_orders_composite ON orders(customer_id, order_date);

✓ Step 2: DONE
  Query now meets performance constraints.

▶ Performance Metrics
────────────────────────────────────────────────────────────────────────────
  total_cost: 142.5
  execution_time_ms: 2.3
  bottlenecks_found: 0

Optimize another query? (yes/no):

INTERACTIVE CONTROLS
--------------------

During query input:
  • Type query on multiple lines
  • Press Enter for new line
  • Type 'GO' and press Enter to submit
  • Type 'EXIT' or 'QUIT' to exit

During optimization:
  • Press Ctrl+C to interrupt current optimization
  • Wait for completion to see results

OUTPUT INTERPRETATION
---------------------

Status Colors:
  GREEN  - PASS / SUCCESS / Completed actions
  RED    - FAIL / CRITICAL / Failed actions
  YELLOW - WARNING / In progress / Medium priority
  CYAN   - Information / Queries / DDL statements
  BLUE   - Secondary information

Action Types:
  CREATE_INDEX    - Creating a database index
  REWRITE_QUERY   - Modifying query structure
  RUN_ANALYZE     - Updating table statistics
  DONE            - Optimization complete
  FAILED          - Cannot optimize further

Priorities:
  CRITICAL - Must fix immediately (logic errors)
  HIGH     - Significant performance issue
  MEDIUM   - Optimization opportunity
  LOW      - Minor improvement or no action needed

TROUBLESHOOTING
---------------

Issue: "ANTHROPIC_API_KEY environment variable not set"
Fix:   export ANTHROPIC_API_KEY='your-api-key-here'

Issue: "Database connection failed"
Fix:   Verify connection string and database accessibility
       Test with: psql <connection-string>

Issue: "Query analysis failed: syntax error"
Fix:   Check SQL syntax before submitting
       The agent cannot fix syntax errors

Issue: "Timeout exceeded"
Fix:   Increase --max-time-ms or simplify query
       Check if database is responsive

Issue: "Agent stuck repeating same action"
Fix:   The agent will automatically stop after detecting loops
       Review database permissions for DDL execution

ADVANCED USAGE
--------------

1. Batch Processing (non-interactive):

   Create a script that pipes queries to the CLI:

   #!/bin/bash
   export ANTHROPIC_API_KEY='...'

   for query in "SELECT * FROM users;" "SELECT * FROM orders;"; do
       echo "$query"
       echo "GO"
       echo "no"
   done | python optimize_cli.py --db-connection postgresql://localhost/db

2. Saving Results:

   The CLI outputs to stdout, so you can redirect:

   python optimize_cli.py > optimization_log.txt 2>&1

3. Custom Constraints Per Query:

   Start the CLI with different flags for different workloads:

   # OLTP workload (fast queries, strict constraints)
   python optimize_cli.py --max-cost 1000 --max-time-ms 100

   # OLAP workload (analytical queries, relaxed constraints)
   python optimize_cli.py --max-cost 1000000 --max-time-ms 300000

INTEGRATION
-----------

The CLI uses the same agent as the BIRD-CRITIC evaluation system.
All optimizations use:

- Phase 1: QueryOptimizationTool (EXPLAIN analysis)
- Phase 2: SQLOptimizationAgent (autonomous optimization)
- Extended thinking mode (8000 token budget)
- Claude Sonnet 4.5 model

For programmatic usage, see:
- run_agent.py - Basic agent usage examples
- src/agentic_dba/agent.py - Full agent API

LIMITATIONS
-----------

1. PostgreSQL only (MySQL/SQL Server not supported)
2. Requires CREATE INDEX privilege for index creation
3. Cannot fix SQL syntax errors (only optimize valid queries)
4. Limited to EXPLAIN-based optimization (no query execution)
5. Autonomous mode may not always find optimal solution

SUPPORT
-------

For issues or questions:
1. Check CLAUDE.md for architecture details
2. Review test_cli.py for validation examples
3. See run_agent.py for programmatic usage
4. Check GitHub issues for known problems

LICENSE
-------

See project LICENSE file for terms and conditions.

================================================================================
                            Happy Optimizing!
================================================================================
